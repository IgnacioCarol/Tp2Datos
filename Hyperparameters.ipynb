{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Library for splitting data\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#Library for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary with the best hyperparameters for each model\n",
    "#hyperparameters = {\n",
    "    #'randomForest' : ,\n",
    "    #'xgboost' : ,\n",
    "    #'decissionTreClassifier' : ,\n",
    "    #'knn' : ,\n",
    "    #'svm': ,\n",
    "    #'lgb' : ,\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function thar returns the best hyperparameters for each model\n",
    "#def getHyperparameters(model):\n",
    "    #return hyperparameters['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>users_tagged</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>links</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>tweet_size</th>\n",
       "      <th>...</th>\n",
       "      <th>users_tagged_minMaxNorm</th>\n",
       "      <th>hashtags_minMaxNorm</th>\n",
       "      <th>hashtags_natNat</th>\n",
       "      <th>users_tagged_natNat</th>\n",
       "      <th>links_natNat</th>\n",
       "      <th>Porn_words_natNat</th>\n",
       "      <th>links_hash_natNat</th>\n",
       "      <th>links_users_natNat</th>\n",
       "      <th>hash_users_natNat</th>\n",
       "      <th>norm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>us</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>20.505016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>fire</td>\n",
       "      <td>la</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.093579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>unknown</td>\n",
       "      <td>resident asked shelter place notified oficers ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.676623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>california</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>20.790918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>smoke</td>\n",
       "      <td>alaska</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>28.465530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     keyword    location  \\\n",
       "0   1  earthquake          us   \n",
       "1   4        fire          la   \n",
       "2   5  evacuation     unknown   \n",
       "3   6  evacuation  california   \n",
       "4   7       smoke      alaska   \n",
       "\n",
       "                                                text  target  users_tagged  \\\n",
       "0         deed reason earthquake may allah forgive u       1             0   \n",
       "1              forest fire near la ronge sask canada       1             0   \n",
       "2  resident asked shelter place notified oficers ...       1             0   \n",
       "3  people receive wildfire evacuation order calif...       1             0   \n",
       "4  got sent photo ruby alaska smoke wildfire pour...       1             0   \n",
       "\n",
       "   hashtags  links  tweet_length  tweet_size  ...  users_tagged_minMaxNorm  \\\n",
       "0         1      0            69           5  ...                      0.0   \n",
       "1         0      0            38           0  ...                      0.0   \n",
       "2         0      0           133          10  ...                      0.0   \n",
       "3         1      0            65           5  ...                      0.0   \n",
       "4         2      0            88           5  ...                      0.0   \n",
       "\n",
       "   hashtags_minMaxNorm  hashtags_natNat  users_tagged_natNat  links_natNat  \\\n",
       "0             0.076923         0.142857                  0.0           0.0   \n",
       "1             0.000000         0.000000                  0.0           0.0   \n",
       "2             0.000000         0.000000                  0.0           0.0   \n",
       "3             0.076923         0.142857                  0.0           0.0   \n",
       "4             0.153846         0.222222                  0.0           0.0   \n",
       "\n",
       "   Porn_words_natNat  links_hash_natNat  links_users_natNat  \\\n",
       "0                0.0           0.142857                 0.0   \n",
       "1                0.0           0.000000                 0.0   \n",
       "2                0.0           0.000000                 0.0   \n",
       "3                0.0           0.142857                 0.0   \n",
       "4                0.0           0.222222                 0.0   \n",
       "\n",
       "   hash_users_natNat      norm2  \n",
       "0           0.142857  20.505016  \n",
       "1           0.000000  15.093579  \n",
       "2           0.000000  30.676623  \n",
       "3           0.142857  20.790918  \n",
       "4           0.222222  28.465530  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainCSV = pd.read_csv('./forHiper')\n",
    "trainCSV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCSV = trainCSV.iloc[:, 4:]\n",
    "x, y = trainCSV.iloc[:,1:], trainCSV.iloc[:,0]  #X tiene que tener todos los features distintos al target\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searchs for the best hyperparameters\n",
    "def findHyperparameters(xTrain, yTrain, model, param_grid, cv, vb, nj):\n",
    "    \n",
    "    grid = GridSearchCV(estimator = model, param_grid = param_grid, scoring = 'roc_auc', cv = cv, verbose = vb, n_jobs = nj)\n",
    "    grid.fit(xTrain, yTrain)\n",
    "    return grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/optimizing-hyperparameters-in-random-forest-classification-ec7741f9d3f6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [100, 300, 500, 800, 1200],\n",
    "    'max_depth' : [5, 8, 15, 25, 30],\n",
    "    'min_samples_split' : [2, 5, 10, 15, 100],\n",
    "    'min_samples_leaf' : [1, 2, 5, 10],\n",
    "    'criterion' : ['gini','entropy']\n",
    "}\n",
    "\n",
    "RC = RandomForestClassifier()\n",
    "bestParametersRF = findHyperparameters(xTrain, yTrain, RC, param_grid, 3, 1, -1) #bestParametersRF\n",
    "bestParametersRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = 3\n",
    "param_grid = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "}\n",
    "XGB = XGBClassifier()\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "bestParametersXGB = findHyperparameters(xTrain, yTrain, XGB, param_grid, skf.split(xTrain, yTrain), 3, 4)\n",
    "bestParametersXGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decission Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/mayu0116/hyper-parameters-tuning-of-dtree-rf-svm-knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11],\n",
    "          'random_state':[123]}\n",
    "\n",
    "DTC = tree.DecisionTreeClassifier(min_samples_split = 10)\n",
    "bestParameteresDTC = findHyperparameters(xTrain, yTrain, DTC, param_grid, 3, 1, -1)\n",
    "bestParameteresDTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/mayu0116/hyper-parameters-tuning-of-dtree-rf-svm-knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {'n_neighbors':[5,6,7,8,9,10],\n",
    "          'leaf_size':[1,2,3,5],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
    "          'n_jobs':[-1]}\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "bestParameteresKNN = findHyperparameters(xTrain, yTrain, KNN, param_grid, 3, 1, 1)\n",
    "bestParameteresKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/mayu0116/hyper-parameters-tuning-of-dtree-rf-svm-knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "param_grid = {'C': [6,7,8,9,10,11,12], \n",
    "          'kernel': ['linear','rbf']}\n",
    "\n",
    "SVC = svm.SVC()\n",
    "bestParameteresSVC = findHyperparameters(xTrain, yTrain, SVC, param_grid, 3, 1, -1)\n",
    "bestParameteresSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mlfromscratch.com/gridsearch-keras-sklearn/#/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 700, 1000],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [15,20,25],\n",
    "    'num_leaves': [50, 100, 200],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'min_split_gain': [0.3, 0.4],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'subsample_freq': [20]\n",
    "}\n",
    "\n",
    "LGBM = lgb.LGBMClassifier()\n",
    "\n",
    "bestParameteresLGBM = findHyperparameters(xTrain, yTrain, LGBM, param_grid, 5, 2, -1)\n",
    "bestParameteresLGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@panjeh/scikit-learn-hyperparameter-optimization-for-mlpclassifier-4d670413042b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "MLP = MLPClassifier(max_iter=100)\n",
    "\n",
    "bestParameteresMLP = findHyperparameters(xTrain, yTrain, MLP, param_grid, 5, 2, -1)\n",
    "bestParameteresMLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
